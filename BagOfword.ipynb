{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d8faea-1673-4f91-874c-d5290c4dc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c335489-3676-4207-83bf-7215e871c0b2",
   "metadata": {},
   "source": [
    "TERMS TO REMEBER\n",
    "<H1>Corpus Document Vocabulary</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa165056-1755-4ced-af94-c0d945ebb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus=[\n",
    "    'This is first document.',\n",
    "    'This document is second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d8fd3d-1b9c-46ea-9852-7b251859ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()\n",
    "x=vectorizer.fit(corpus)        #creating Vocablury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1316dba-c360-4a79-b19c-744379ce221a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'the': 6,\n",
       " 'third': 7,\n",
       " 'one': 4}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.vocabulary_  #vocabulary consists of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c70c7e7-2ae2-45af-8b79-c38a2c6b7df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is first document.',\n",
       " 'This document is second document.',\n",
       " 'And this is the third one.',\n",
       " 'Is this the first document']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd485ea-7a7f-404d-a583-5167cff0ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 1)\t2\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 8)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 8)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.transform(corpus)) #CSR Matrix in this result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f424d9c-90bf-4c5f-938f-1a19f1984db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 0, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(corpus).toarray() # array form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63114861-f508-4852-8164-0cb8650a0b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 0, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(corpus).toarray() # array form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a908006-5e76-45f4-bfdf-8cc25ab7cc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The getsizeof function takes an object as an argument and returns the memory size of that object in bytes.\n",
    "from sys import getsizeof\n",
    "getsizeof(vectorizer.transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "939f47d7-8c8f-4935-b9a4-6ca4c1f965b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "getsizeof(vectorizer.transform(corpus))#we can see the diffrence in memory size of array form and csr matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813cb8e-b21d-4977-9f38-036aaad31359",
   "metadata": {},
   "source": [
    "Creating function for applying bag of words by ourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb722b4-4842-4c5d-b0e2-73c36c2d570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(corpus):\n",
    "    \n",
    "    uniqueWords = set()\n",
    "    for document in corpus:\n",
    "        document = document.split()\n",
    "        for word in document:\n",
    "            if len(word) < 2:\n",
    "                    continue\n",
    "            uniqueWords.add(word)\n",
    "            \n",
    "   \n",
    "    vocab = {word:index for index,word in enumerate(uniqueWords)}\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3d48f8-11ec-4d47-af3c-a0e97bb69047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not': 0, 'is': 1, 'good': 2, 'pen': 3, 'that': 4, 'book': 5, 'this': 6}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=[\n",
    "    \"this is book not pen\",\n",
    "    \"this pen is good\" ,\n",
    "    \"this book is not that book\"\n",
    "]\n",
    "\n",
    "fit(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b4b48-ba96-47f0-b41e-165f2d882d61",
   "metadata": {},
   "source": [
    "<h2>Counter Method from scipy.sparse</h2>\n",
    "The Counter class from the collections module counts the occurrences of each element in a collection (like a list or a string) and stores them in a dictionary-like structure where the keys are the elements and the values are their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85c333fd-d647-48ec-b4f9-0b0ca3cceb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This': 1, 'Pizza': 1, 'Is': 1, 'quite': 1, 'depressing': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "dict(Counter([\"This\",\"Pizza\",\"Is\",\"quite\",\"depressing\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8597b93a-4942-4efa-90a9-c91ee84f661f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'book', 'not', 'this', 'pen']\n",
      "Counter({'this': 2, 'is': 1, 'book': 1, 'not': 1, 'pen': 1})\n",
      "\n",
      "\n",
      "\n",
      "['this', 'is', 'pen', 'good']\n",
      "Counter({'this': 1, 'is': 1, 'pen': 1, 'good': 1})\n",
      "\n",
      "\n",
      "\n",
      "['this', 'book', 'is', 'not', 'that', 'book']\n",
      "Counter({'book': 2, 'this': 1, 'is': 1, 'not': 1, 'that': 1})\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts=[\n",
    "    \"this is book not this pen\",\n",
    "    \"this is pen good\",\n",
    "    \"this  book is not that book\",\n",
    "]\n",
    "for document in texts:\n",
    "    document=document.split()\n",
    "    print(document)\n",
    "    print(Counter(document))\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14dbdb-8cc0-4f66-b33f-c89b4787331b",
   "metadata": {},
   "source": [
    "<h2>Get Method in Dictionary</h2>\n",
    "The get method in a Python dictionary retrieves the value associated with a specified key, returning a default value (e.g., None) if the key is not found, without raising an error. It is used as dict.get(key, default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "143d765c-6da5-48f5-8f7e-2428f5507e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dict1={\"anish\":1,\"saif\":2,\"kalim\":3}\n",
    "print(dict1.get(\"anish\"))  ## will return the value from dict1 where key is \"anish\"\n",
    "print(dict1.get(\"imam\"))# it will return None as there is no \"imam\" value in dict1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00aca08-ce18-4c99-b1aa-127a24b0bf4f",
   "metadata": {},
   "source": [
    "Writing transform method  <br>\n",
    "Given a corpus and a vocabulary and we have to apply BOW by ourself and results should be in csr format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27c7ccf3-f26d-4b3d-a9d4-8c7999e4b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(corpus,vocab):\n",
    "   \n",
    "   rows = []\n",
    "   columns = []\n",
    "   values = []\n",
    "   for doc_idx, doc in enumerate(corpus):\n",
    "       doc = doc.split()\n",
    "       word_freq= dict(Counter(doc))\n",
    "       for word, freq in word_freq.items():  # for each unique word in the review.                \n",
    "           if len(word) < 2:\n",
    "                continue\n",
    "\n",
    "           col_index = vocab.get(word)\n",
    "           if col_index is not None:\n",
    "             rows.append(doc_idx)\n",
    "             columns.append(col_index)\n",
    "             values.append(freq) \n",
    "\n",
    "   return csr_matrix((values, (rows,columns) ))         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78a36e48-155c-40b5-8736-01b77cab6ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t2\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 5)\t2\n",
      "  (2, 6)\t1\n"
     ]
    }
   ],
   "source": [
    "vocabulary=fit(texts)\n",
    "print(transform(texts , vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c3234-39f9-43e2-bd75-b2b3d2c36fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
